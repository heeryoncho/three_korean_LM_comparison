{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05f27b6",
   "metadata": {},
   "source": [
    "## 한국어 학습 모델별 한국어 쓰기 답안지 점수 구간 예측 성능 비교\n",
    "### 세 가지 한국어 딥러닝 언어모델의 성능을 비교: KoBERT, KR-BERT, KcBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e276c0",
   "metadata": {},
   "source": [
    "1. 먼저 아래의 URL로부터 유학생 한국어 쓰기 답안지 실험 데이터를 다운로드 한 후, jupyter notebook에 업로드 함.\n",
    "\n",
    "http://aihumanities.org/ko/archive/data/?vid=1\n",
    "\n",
    "(웹사이트의 게시판 페이지의 첨부파일 'korean_essay_score_range_prediction_dataset.zip'을 클릭하여 다운로드.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aba838",
   "metadata": {},
   "source": [
    "2. 아래의 셀을 실행하여 다운로드한 데이터의 압축을 풀고, <font color='red'>**폴더명을 'data'로 변경**</font>함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd242af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! unzip ./korean_essay_score_range_prediction_dataset.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device\n",
    "#print('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58602c57",
   "metadata": {},
   "source": [
    "3. 테스트 데이터를 정의한 폴더(folder)와 k-fold cross validation을 위한 k (여기서는 k=i로 정의)를 설정함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 테스트 데이터를 설정\n",
    "folder = 'happiness'   # all, job, happiness 중 하나를 설정\n",
    "i =  0    # k-fold cross validation을 위한 숫자 설정 [0-6] \n",
    "add_train = ''\n",
    "\n",
    "data_train = pd.read_csv(\"data/{}/train_{}.txt\".format(folder, i), sep='\\t')\n",
    "data_valid = pd.read_csv(\"data/{}/val_{}.txt\".format(folder, i), sep='\\t')\n",
    "data_test = pd.read_csv(\"data/{}/test_{}.txt\".format(folder, i), sep='\\t')\n",
    "data_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e4b989",
   "metadata": {},
   "source": [
    "4. 만약 훈련 데이터에 다른 주제의 데이터를 추가하는 경우, 아래의 add_train에서 하나를 선택함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 실험을 위해 훈련 데이터를 추가\n",
    "# 단, folder='all'을 선택한 경우는 데이터를 추가하지 않음 \n",
    "\n",
    "#add_train = 'economic'   # 경제 데이터를 훈련 데이터에 추가\n",
    "#add_train = 'success'   # 성공 데이터를 훈련 데이터에 추가\n",
    "#add_train = 'happiness'  # 행복 데이터를 훈련 데이터에 추가\n",
    "#add_train = 'job'   # 직업 데이터를 훈련 데이터에 추가\n",
    "#add_train = ['success', 'economic', 'happiness']   # 성공, 경제, 행복 데이터를 훈련 데이터에 추가\n",
    "#add_train = ['success', 'economic', 'job']   # 성공, 경제, 직업 데이터를 훈련 데이터에 추가\n",
    "\n",
    "if isinstance(add_train, list):\n",
    "    for fn in add_train:\n",
    "        data_train_add = pd.read_csv(\"data/{}.txt\".format(fn), sep='\\t')\n",
    "        data_train = pd.concat([data_train, data_train_add], ignore_index=True)\n",
    "    add_train = '_' + '_'.join(add_train)\n",
    "\n",
    "elif add_train in ['success', 'economic', 'job', 'happiness']:\n",
    "    data_train_add = pd.read_csv(\"data/{}.txt\".format(add_train), sep='\\t')\n",
    "    data_train = pd.concat([data_train, data_train_add], ignore_index=True)\n",
    "    add_train = '_' + add_train\n",
    "\n",
    "#print(add_train)    \n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb47e9b",
   "metadata": {},
   "source": [
    "5. 한국어 딥러닝 언어모델을 아래의 **model_name**에서 선택함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6479a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import set_seed\n",
    "\n",
    "set_seed(42)   # 재현성을 위해 seed를 설정\n",
    "\n",
    "# KoBERT, KR-BERT, KcBERT 중 모델 하나를 선택\n",
    "\n",
    "#model_name = \"monologg/kobert\"\n",
    "#model_name = \"snunlp/KR-BERT-char16424\"\n",
    "model_name = \"beomi/kcbert-base\"\n",
    "\n",
    "if model_name == \"monologg/kobert\":\n",
    "    output_model_folder = 'result_kobert'    \n",
    "elif model_name == \"snunlp/KR-BERT-char16424\":\n",
    "    output_model_folder = 'result_krbert'\n",
    "elif model_name == \"beomi/kcbert-base\":\n",
    "    output_model_folder = 'result_kcbert'    \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"beomi/kcbert-base\":\n",
    "    max_len = 300   # KcBERT\n",
    "else:    \n",
    "    max_len = 512   # KoBERT, KR-BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example, padding='max_length', truncation=True, max_length=max_len)\n",
    "\n",
    "encodings_train = data_train[\"document\"].map(tokenize_function)\n",
    "encodings_valid = data_valid[\"document\"].map(tokenize_function)\n",
    "encodings_test = data_test[\"document\"].map(tokenize_function)\n",
    "#print(encodings_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbadb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data_train[\"label\"])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_train = le.transform(data_train[\"label\"])\n",
    "y_valid = le.transform(data_valid[\"label\"])\n",
    "y_test = le.transform(data_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.encodings[idx]\n",
    "        item = {}\n",
    "        item['input_ids'] = torch.LongTensor(data['input_ids'])\n",
    "        item['attention_mask'] = torch.LongTensor(data['attention_mask'])\n",
    "        item['token_type_ids'] = torch.LongTensor(data['token_type_ids'])\n",
    "        item['labels'] = torch.LongTensor([self.labels[idx]])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929fc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomTextDataset(encodings_train, y_train)\n",
    "dataset_valid = CustomTextDataset(encodings_valid, y_valid)\n",
    "dataset_test = CustomTextDataset(encodings_test, y_test)\n",
    "#dataset_train.encodings[0][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 24\n",
    "train_dataloader = DataLoader(dataset_train, shuffle=True, batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(dataset_valid, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c88b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name, num_labels=4)\n",
    "model.dropout = torch.nn.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92bb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "learning_rate = 1e-5\n",
    "warmup_ratio = 0.1\n",
    "max_grad_norm = 1\n",
    "num_epochs = 50\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "warmup_step = int(num_training_steps * warmup_ratio)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"cosine\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup_step,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba76145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture cap --no-stderr\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_metric\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "print(\"------{}{}_{}------\".format(folder, add_train, i))\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"].flatten())\n",
    "    acc_eval = metric.compute()\n",
    "    print(\"epoch {} val acc {}\".format(epoch+1, acc_eval[\"accuracy\"]))\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"].flatten())\n",
    "    acc_test = metric.compute()\n",
    "    print(\"epoch {} test acc {}\".format(epoch+1, acc_test[\"accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바로 위의 셀의 맨 위에 있는 '%%capture cap --no-stderr'의 코멘트를 해제한 뒤,\n",
    "# 아래의 파일 저장 코드를 활성화 하면,\n",
    "# epoch 별 validation & test accuracy 가 기록된 파일이 언어모델 폴더에 저장됨 \n",
    "\n",
    "#with open('{}/{}{}_{}a.txt'.format(output_model_folder, folder, add_train, i), 'w') as f:\n",
    "#     f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상단의 Kernel 메뉴에서 Restart & Run All 을 실행하는 경우, 위의 셀까지 실행이 다 끝나면 알람이 울림\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "sound = np.sin(2*np.pi*400*np.arange(10000*2)/10000)\n",
    "ipd.Audio(sound, rate=10000, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098b124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = []\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    y_pred += list(torch.argmax(logits, dim=-1).to('cpu').numpy())\n",
    "\n",
    "def num_to_grade(y_label_num):\n",
    "    y_label_letter = []\n",
    "    for val in y_label_num:\n",
    "        if val == 0:\n",
    "            y_label_letter.append('D')\n",
    "        elif val == 1:\n",
    "            y_label_letter.append('C')\n",
    "        elif val == 2:\n",
    "            y_label_letter.append('B')\n",
    "        elif val == 3:\n",
    "            y_label_letter.append('A')\n",
    "    return y_label_letter            \n",
    "\n",
    "y_true_letter = num_to_grade(y_test)\n",
    "y_pred_letter = num_to_grade(y_pred)\n",
    "\n",
    "# 50 epoch 때의 모델의 테스트 데이터 분류 성능을 표시함\n",
    "print('accuracy:', accuracy_score(y_true_letter, y_pred_letter))\n",
    "\n",
    "# confusion matrix 생성\n",
    "cm = confusion_matrix(y_true_letter, y_pred_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix 그림을 출력\n",
    "# https://stackoverflow.com/questions/60480777/plotting-already-calculated-confusion-matrix-using-python\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Classes\n",
    "classes = ['A', 'B', 'C', 'D']\n",
    "\n",
    "figure, ax = plot_confusion_matrix(conf_mat = cm,\n",
    "                                   class_names = classes,\n",
    "                                   #show_absolute = False,\n",
    "                                   #show_normed = False,\n",
    "                                   colorbar = False)\n",
    "ax.set_title(\"KcBERT Happiness (Acc: 78.57%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b14a03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
